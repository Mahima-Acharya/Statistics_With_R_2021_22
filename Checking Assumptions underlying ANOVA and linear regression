### Stats with R Exercise sheet 7

#############################################################################
  #Week8: Checking Assumptions underlying ANOVA and linear regression
#############################################################################

## This exercise sheet contains the exercises that you will need to complete and 
## submit by 23:55 on Sunday, December 19. Write the code below the questions. 
## If you need to provide a written answer, comment this out using a hashtag (#). 
## Submit your homework via cms

## Please write below your (and your teammates) name, matriculation number. 
## Name: Mark Sebastian Mikleu, George Daniel Mikleu, Mahima Mahabaleshwar Acharya
## Matriculation number: 2580499, 2580498, 7003016
## Team: 56

###############################################################################
###############################################################################

## The following line of code clears your workspace.

rm(list = ls())


library(boot)
library(ggplot2)
library(dplyr)
library(car)
library(languageR)


#############################################################################
### Exercise 1
#############################################################################

#############################################################################
### Please, use ggplot to make plots in all exercises unless specified differently!
#############################################################################


##  We will again be using the lexdec dataset from library languageR. 
##  In sheet 4, we ran a t-test to test for differences in RT after a word vs after a non word.
##  In sheet 5, we looked at correlations between RT and frequency and length. In this sheet we will 
##  combine these analyses, look for interactions and again look at model assumptions
##  and model diagnostics

## a) Load the dataset lexdec from package languageR and store it in a variable called data

data <- lexdec

## b) Run a simple regression, just including Frequency as predictor and RT as the dependent variable
##  Store it in lm1

lm1 <- lm(RT ~ Frequency, data = data)

## c) Report and explain the effect of Frequency

summary(lm1)
###!!! use the significance reporting format taught in the lecture:
# The p-value is smaller than 0.05 following from this we know that our model is significant.
# The proportion of the total variance explained by our model is 0.05123.
# Intercept: If the word frequency is 0 then we have a RT of 6.588778.
# If the word frequency increases by 1 the RT decreases by 0.042872.

## d) Make a scatterplot of RT by Frequency, including the regression line

ggplot(data, aes(x = Frequency, y = RT)) +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE)

## e) Next, fit a model including Frequency and PrevType as predictors, store it in lm2

lm2 <- lm(RT ~ Frequency + PrevType, data = data)

## f) Report and explain the effects of Frequency and PrevType.

summary(lm2)
###!!! again, report format and you'd have discussed the significance of each effect:
# The p-value is smaller than 0.05 following from this we know that our model is significant.
# The proportion of the total variance explained by our model is 0.06965.
# Intercept: If the word frequency is 0 and the prev type is a nonword then we have a RT of 6.62193.
# If the word frequency increases by 1 the RT decreases by 0.04316.
# If the prev type is word then the RT decreases by 0.06557.

##  Next we want to plot a model where both predictors are shown. For those we first store the predicted values
## of our model:
 data$RT_pred = fitted(lm2)

## g) Now, plot the original data (RT by Frequency with different colors for PrevType), but use the 
## fitted values (RT_pred) inside geom_smooth() or geom_line(), otherwise, it will display regression lines 
## assuming an interaction
## The resulting plot should show the data points in different colors and two parallel regression lines.
 
 ggplot(data, aes(x = Frequency, y = RT, colour = PrevType)) +
   geom_jitter() +
   geom_line(aes(y = RT_pred), size = 1)

## h) Run a regression model that includes also the interaction between Frequency and PrevType and store it
##  as lm3
 
lm3 <- lm(RT ~ Frequency * PrevType, data = data)

## i) Plot the results of the model! (This time no need to specify the pred data set)

ggplot(data, aes(x = Frequency, y = RT, colour = PrevType)) +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE)

## j) Report the results of lm3 and interpret with the help of the graph in i)

summary(lm3)
###!!! missed insignificance of PrevType effect due to not discussing effects separately:

# The p-value is smaller than 0.05 following from this we know that our model is significant.
# The proportion of the total variance explained by our model is 0.07202.
# Intercept: If the word frequency is 0 and the prev type is nonword then we have a RT of 6.577750.
# If the word frequency increases by 1 the RT decreases by 0.033890.
# If the prev type is word then the RT increases by 0.022098.

# The graph in i) suggests that the effect of the frequency on the 
# reaction time depends on the previous type.
# The larger the frequency gets the smaller the reaction time gets.
# This effect is stronger for words than for nonwords.
# The difference becomes more apparent for larger frequencies.
# The interaction between frequency and prev type is significant. (p<0.05)

## k) Do model checking on your model lm3, i.e. inspect the standard model plots provided by R (no ggplot, 
## see lecture notes for syntax)

par(mfcol=c(2,3))
plot(lm3, which = seq(1,6))

## l) Interpret what you see in k) and possibly suggest further steps

# In the Normal Q-Q plot we see that many data points aren't following the line 
# and thus the residuals are not normally distributed.
# We could look at the outliers 1194, 1619 and 1620 which were named by R.

# Looking at the Residuals vs Fitted plot we see that the residuals aren't equally distributed.
# The larger the fitted value the more values and wider spread out the residuals are. (larger variance)
# We could look at the outliers 1194, 1619 and 1620 which were named by R.

# We can interpret the Scale-Location plot the same way as the Residuals vs Fitted plot
# but with a less wide spread.

# The Residuals vs Leverage plot and the Cook's dist vs Leverage plot 
# are used to identify highly influential outliers (bad outliers).
# These points have high cook's distance.
# We have to look at these data points and possibly remove them.

# The Cook's distance plot tells us how influential the different points are by
# giving us their cook's distance.

## m) So, what assumptions are violated in the model as it is? Consider both your results from l and what you know 
##  about the data set from previous analyses.

# From the plots we can conclude following:

# The Normality of residuals assumption is violated.
# The Homogeneity of variance assumption is violated.
# There are a few bad outliers.

# From previous analyses we know following:

# There is no Independence of observations because each subject in the data set
# gets multiple words (repeated measures)

vif(lm3)

# We get a very high vif for the PrevType meaning that the PrevType is 
# highly correlated with the frequency and thus the assumption of uncorrelated predictors is violated.
